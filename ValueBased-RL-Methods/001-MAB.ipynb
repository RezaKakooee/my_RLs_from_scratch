{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75423826-60ba-424b-80c2-96aa687a1847",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1242d3-1b18-472a-9da5-3cc243edf677",
   "metadata": {},
   "source": [
    "Multi-Armed Bandit (MAB) is a form of Reinforcement Learning (RL) problem with a single state and multiple actions in which, like the all form of RL problems, the goal is to maximize the reward in a time horizon.\n",
    "\n",
    "In MAB, the agent is confronted with multiple actions selecting each of which leads to a scalar reward drawn from an unknown distribution. \n",
    "\n",
    "Selecting action is costly, and the agent goal is to maximize the long term reward.\n",
    "\n",
    "The challenge is that the underlying distributions are unknown, so feeding the best actions require efficiently balancing between exploration and exploitation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9fd67-fa1c-473e-a81e-0cfdf7fbf105",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5ad735-465f-4c22-84a0-036f9ba8b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6e35a-bf54-4c32-9e6a-49d01ce060d6",
   "metadata": {},
   "source": [
    "## 1. Defining Bandit Game Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c958a-05a1-4124-b2f9-8cf8b68fba9f",
   "metadata": {},
   "source": [
    "In this section, we want to define the Bandit Game class. \n",
    "\n",
    "But before that, since each bandit machine follows a distribution, let's first implement two types of distributions: Normal and Bernoulli distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74f84a-2c1a-40df-806e-ba786c61ddcc",
   "metadata": {},
   "source": [
    "### 1.1. Defining distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1245b8-b82f-4db6-baf5-1cadf8d15cfb",
   "metadata": {},
   "source": [
    "#### 1.1.1. Normal Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74a2673-4496-4c78-8ef5-1e01b85a1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "    def __init__(self, mean=0, std=1):\n",
    "        \"\"\"\n",
    "        Define a Guassian distribution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mean : float, optional\n",
    "            The mean of normal distribution. The default is 0.\n",
    "        std : float, optional\n",
    "            std of normal distribution. The default is 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Draw a single sample from the normal distribution\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reward : float\n",
    "            A sample from the distribution\n",
    "        \"\"\"\n",
    "        reward = np.random.normal(self.mean, self.std)\n",
    "        reward = np.round(reward, 1) # rounding the reward to have consistant resutls\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ebffb-16ad-4df2-a7e6-19e2fb4a65f5",
   "metadata": {},
   "source": [
    "#### 1.1.2. Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2936538d-631b-4563-a790-380082dad942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    def __init__(self, p):\n",
    "        \"\"\"\n",
    "        Define a Bernoulli distribution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        p : a float number between 0 to 1\n",
    "            p represents the probability of choosing 1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Draw a single sample from the Bernoulli distribution\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reward : binary: 0 or 1\n",
    "            A sample from the distribution\n",
    "        \"\"\"\n",
    "        reward = np.random.binomial(n=1, p=self.p)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad109b-5c01-4343-8e2d-a686c6cc25e9",
   "metadata": {},
   "source": [
    "### 1.2. Defining Bandit Game class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60288c37-9088-4060-9c0d-3d605790f0d3",
   "metadata": {},
   "source": [
    "Now, we can define the bandit game class which receives some distributions and allows the user to pull them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd597ed-50f2-40ec-a4f7-f47f1cb6f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditGame:\n",
    "    def __init__(self, bandits: list):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        bandits : list\n",
    "            a list of distributions for bandits, each of which has an unkown \n",
    "            distribution that might be any distribution like Normal and Betta.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.bandits = bandits\n",
    "        \n",
    "        ## shuffle the list to make an \n",
    "        np.random.shuffle(self.bandits)\n",
    "\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"\n",
    "        Define some variables to keep track of the reward and timestep\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.rewards = []\n",
    "        self.total_reward = 0\n",
    "        self.avg_reward = 0 # the average reward received sofar\n",
    "        self.time_step = 0\n",
    "\n",
    "    \n",
    "    def _update(self, rew):\n",
    "        \"\"\"\n",
    "        Updating the reward related variables and time_step in each timestep\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rew : float\n",
    "            a float number showing the received reward in the current timestep.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.rewards.append(rew)\n",
    "        self.total_reward += rew\n",
    "        self.avg_reward = np.mean(self.rewards)\n",
    "        self.time_step += 1\n",
    "        \n",
    "        \n",
    "    def _step(self, choice):\n",
    "        \"\"\"\n",
    "        Pulling a machine according to the agent's choice, and updating the \n",
    "        reward related variables and time_step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        choice : int\n",
    "            an integer showing the agent's choice in the current timestep.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rew : flaot\n",
    "            the reward that the pulled machine delivers.\n",
    "\n",
    "        \"\"\"\n",
    "        # sampling a reward from the underlying distribution of the selected bandit\n",
    "        rew = self.bandits[choice].draw() \n",
    "        \n",
    "        self._update(rew)\n",
    "        return rew \n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Printing the rewards\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"\\n- - - You pulled the arms for {self.time_step} times.\")\n",
    "        print(f\"- - - Reward list: {self.rewards}\")\n",
    "        print(f\"- - - Total reward: {self.total_reward}\")\n",
    "        print(f\"- - - Average reward: {self.avg_reward}\")\n",
    "        \n",
    "\n",
    "    def play(self):\n",
    "        print(\"#\"*10 + \"Interactivelly simulate the MAB problem\" + \"#\"*10)\n",
    "        \n",
    "        while True:\n",
    "            print(f\" \\n\\n\\n {'#'}*5 Timestep: {self.time_step}\")\n",
    "            \n",
    "            try:\n",
    "                choice = int(input(f\"Enter a number between 1 to {len(self.bandits)} to select a machine or any other numbers to exit: \")) -1\n",
    "                \n",
    "                if choice in range(0, len(self.bandits)):\n",
    "                    reward = self._step(choice)\n",
    "                    print(f\"--- Mahcine {choice} gave a reward of {reward}\")\n",
    "                    print(f\"--- Average reward sofar is: {self.avg_reward}\")\n",
    "            \n",
    "                else:\n",
    "                    print(\"___ No machine exist with this ID! \")\n",
    "                    break\n",
    "                \n",
    "            except: \n",
    "                print(\"You entered a wrong input, but your rewards were stored!\")\n",
    "                break\n",
    "        \n",
    "        print(\"_\"*7 + \"You teminated the game!\" + \"_\"*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90e459-d62b-4bbb-af70-e2102e2bcd20",
   "metadata": {},
   "source": [
    "## 2. Play with the Bandit machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0d10e-ee13-48c3-91de-04361f61b489",
   "metadata": {},
   "source": [
    "Now, we define some arbitrary normal distributions as the underlying distributions for each bandit machine, and then we instantiate the BanditGame class and play with it for a couple of timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb28e0b-3a79-414e-9dc5-34494771cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define bandit machines with Gaussian dist\n",
    "g_slot_A = Gaussian(5, 3)\n",
    "g_slot_B = Gaussian(6, 2)\n",
    "g_slot_C = Gaussian(1, 5)\n",
    "\n",
    "g_bandits = [g_slot_A, g_slot_B, g_slot_C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6dc9d9-2b8d-4e49-9add-c7a2a6c059f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate the BanditGame\n",
    "g_game = BanditGame(g_bandits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0612d1f8-2585-4a3b-8d82-ebadf6bfd5b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Interactivelly simulate the MAB problem##########\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 0\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 1\n",
      "--- Mahcine 0 gave a reward of 4.0\n",
      "--- Average reward sofar is: 4.0\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 1\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of 4.8\n",
      "--- Average reward sofar is: 4.4\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 2\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 1\n",
      "--- Mahcine 0 gave a reward of 6.5\n",
      "--- Average reward sofar is: 5.1000000000000005\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 3\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 3\n",
      "--- Mahcine 2 gave a reward of 7.7\n",
      "--- Average reward sofar is: 5.75\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 4\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 3\n",
      "--- Mahcine 2 gave a reward of 3.3\n",
      "--- Average reward sofar is: 5.26\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 5\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 3\n",
      "--- Mahcine 2 gave a reward of 4.1\n",
      "--- Average reward sofar is: 5.066666666666666\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 6\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of 4.0\n",
      "--- Average reward sofar is: 4.914285714285714\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 7\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of -1.6\n",
      "--- Average reward sofar is: 4.1\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 8\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 1\n",
      "--- Mahcine 0 gave a reward of 1.6\n",
      "--- Average reward sofar is: 3.822222222222222\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 9\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of 0.3\n",
      "--- Average reward sofar is: 3.4699999999999998\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 10\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 1\n",
      "--- Mahcine 0 gave a reward of 5.9\n",
      "--- Average reward sofar is: 3.6909090909090905\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 11\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 3\n",
      "--- Mahcine 2 gave a reward of 8.9\n",
      "--- Average reward sofar is: 4.124999999999999\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 12\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of -7.4\n",
      "--- Average reward sofar is: 3.238461538461538\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 13\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 1\n",
      "--- Mahcine 0 gave a reward of 6.1\n",
      "--- Average reward sofar is: 3.4428571428571426\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 14\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 2\n",
      "--- Mahcine 1 gave a reward of 5.5\n",
      "--- Average reward sofar is: 3.5799999999999996\n",
      " \n",
      "\n",
      "\n",
      " #*5 Timestep: 15\n",
      "Enter a number between 1 to 3 to select a machine or any other numbers to exit: 0\n",
      "___ No machine exist with this ID! \n",
      "_______You teminated the game!_______\n"
     ]
    }
   ],
   "source": [
    "## Play the game for some timesteps\n",
    "g_game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f0b45e-14f7-4b3d-8e73-b2c726f81f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - You pulled the arms for 15 times.\n",
      "- - - Reward list: [4.0, 4.8, 6.5, 7.7, 3.3, 4.1, 4.0, -1.6, 1.6, 0.3, 5.9, 8.9, -7.4, 6.1, 5.5]\n",
      "- - - Total reward: 53.699999999999996\n",
      "- - - Average reward: 3.5799999999999996\n"
     ]
    }
   ],
   "source": [
    "## Print the final results\n",
    "g_game.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
